# Hand-Sign-Recognition-System
This project implements a hand sign recognition model that detects specific gestures and maps them to functions like rotate, zoom, and place to manipulate a 3D object in real time within a Unity environment.

The model uses MediaPipe Holistic (including FaceMesh and hand landmarks) to extract keypoints and a trained TensorFlow model to classify actions. The recognized gesture triggers changes in the 3D object's orientation, position, or zoom level.

ğŸš€ Features

Real-time Hand Sign Detection â€” Uses MediaPipe Holistic for pose, hand, and face landmark extraction
Action Classification â€” Trained TensorFlow model predicts gestures
3D Object Control â€” Integrates with Unity to perform operations like:
ğŸ”„ Rotate the object
ğŸ” Zoom in / Zoom out
ğŸ“ Place the object
Live Camera Feed â€” Displays real-time video with detected gestures using OpenCV

ğŸ› ï¸ Tech Stack

Programming Language: Python
Libraries:
MediaPipe
 â€” Landmark detection
OpenCV
 â€” Real-time video processing
TensorFlow / Keras
 â€” Gesture classification
NumPy â€” Feature extraction and manipulation
Platform Integration: Unity (3D object control)
